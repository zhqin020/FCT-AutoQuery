#!/usr/bin/env python3
"""
Federal Court Case Scraper - æ¼”ç¤ºè„šæœ¬
è”é‚¦æ³•é™¢æ¡ˆä»¶æŠ“å–å™¨ - æ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨è”é‚¦æ³•é™¢æ¡ˆä»¶æŠ“å–å™¨çš„åŸºæœ¬åŠŸèƒ½ã€‚
This script demonstrates basic usage of the Federal Court Case Scraper.
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.services.case_scraper_service import CaseScraperService
from src.services.export_service import ExportService
from src.lib.logging_config import setup_logging

def demo_basic_scraping():
    """æ¼”ç¤ºåŸºæœ¬çš„æŠ“å–åŠŸèƒ½ / Demonstrate basic scraping functionality."""
    print("ğŸ” è”é‚¦æ³•é™¢æ¡ˆä»¶æŠ“å–å™¨æ¼”ç¤º / Federal Court Case Scraper Demo")
    print("=" * 60)

    # åˆå§‹åŒ–æœåŠ¡ / Initialize services
    scraper = CaseScraperService(headless=True)  # ä½¿ç”¨æ— å¤´æ¨¡å¼ / Use headless mode
    exporter = ExportService(output_dir="./demo_output")

    # ç¤ºä¾‹URL / Example URLs
    test_urls = [
        "https://www.fct-cf.ca/en/court-files-and-decisions/IMM-12345-22",
        "https://www.fct-cf.ca/en/court-files-and-decisions/IMM-67890-23"
    ]

    cases = []

    print("ğŸ“„ å¼€å§‹æŠ“å–æµ‹è¯•æ¡ˆä»¶... / Starting to scrape test cases...")

    for i, url in enumerate(test_urls, 1):
        try:
            print(f"\nğŸ”„ å¤„ç†URL {i}/{len(test_urls)}: {url}")
            print(f"ğŸ”„ Processing URL {i}/{len(test_urls)}: {url}")

            # æ³¨æ„ï¼šè¿™åªæ˜¯æ¼”ç¤ºï¼Œå®é™…URLå¯èƒ½ä¸å­˜åœ¨
            # Note: This is just a demo, actual URLs may not exist
            print("âš ï¸  æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºï¼Œå®é™…URLå¯èƒ½æ— æ³•è®¿é—®")
            print("âš ï¸  Note: This is a demo, actual URLs may not be accessible")

            # è¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æ¡ˆä¾‹æ•°æ®ç”¨äºæ¼”ç¤º
            # Here we create mock case data for demonstration
            from datetime import date, datetime
            from src.models.case import Case

            mock_case = Case(
                case_id=url,
                case_number=f"IMM-{12345 + i - 1}-22",
                title=f"Demo Case {i}",
                court="Federal Court",
                date=date(2023, 6, 15),
                html_content=f"<html><body>Demo case {i} content</body></html>",
                scraped_at=datetime.now()
            )

            cases.append(mock_case)
            print(f"âœ… æ¨¡æ‹Ÿæ¡ˆä¾‹åˆ›å»ºæˆåŠŸ: {mock_case.case_number}")
            print(f"âœ… Mock case created: {mock_case.case_number}")

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            print(f"âŒ Processing failed: {e}")

    # å¯¼å‡ºç»“æœ / Export results
    if cases:
        print(f"\nğŸ“Š å¯¼å‡º {len(cases)} ä¸ªæ¡ˆä¾‹... / Exporting {len(cases)} cases...")

        try:
            # å¯¼å‡ºä¸ºJSONå’ŒCSV / Export to JSON and CSV
            files = exporter.export_all_formats(cases, "demo_cases")
            print("âœ… å¯¼å‡ºæˆåŠŸ! / Export successful!")
            print(f"   JSON: {files['json']}")
            print(f"   CSV: {files['csv']}")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            print(f"âŒ Export failed: {e}")

    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆ! / Demo completed!")
    print("ğŸ“ æ£€æŸ¥ demo_output/ ç›®å½•æŸ¥çœ‹ç»“æœæ–‡ä»¶")
    print("ğŸ“ Check demo_output/ directory for result files")

    # æ¸…ç†èµ„æº / Cleanup resources
    scraper.cleanup()

def demo_url_validation():
    """æ¼”ç¤ºURLéªŒè¯åŠŸèƒ½ / Demonstrate URL validation functionality."""
    print("\nğŸ” URLéªŒè¯æ¼”ç¤º / URL Validation Demo")
    print("=" * 40)

    from src.lib.url_validator import URLValidator

    test_urls = [
        ("https://www.fct-cf.ca/en/court-files-and-decisions/IMM-12345-22", True),
        ("https://www.fct-cf.ca/en/court-files-and-decisions/IMM-67890-23", True),
        ("https://example.com/case/123", False),
        ("https://www.fct-cf.ca/other-path/IMM-12345-22", False),
        ("not-a-url", False),
    ]

    for url, expected in test_urls:
        is_valid, reason = URLValidator.validate_case_url(url)
        status = "âœ…" if is_valid == expected else "âŒ"
        print(f"{status} {url}")
        if not is_valid:
            print(f"   åŸå› : {reason}")

def main():
    """ä¸»å‡½æ•° / Main function."""
    # è®¾ç½®æ—¥å¿— / Setup logging
    setup_logging()

    print("ğŸš€ è”é‚¦æ³•é™¢æ¡ˆä»¶æŠ“å–å™¨æ¼”ç¤ºå¼€å§‹ / Federal Court Case Scraper Demo Starting")
    print()

    try:
        # æ¼”ç¤ºURLéªŒè¯ / Demo URL validation
        demo_url_validation()

        # æ¼”ç¤ºåŸºæœ¬æŠ“å– / Demo basic scraping
        demo_basic_scraping()

    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­ / Demo interrupted by user")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"\nâŒ Error during demo: {e}")
        return 1

    return 0

if __name__ == "__main__":
    sys.exit(main())