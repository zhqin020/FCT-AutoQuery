import pandas as pd
import numpy as np

# Suppress future warning for downcasting
pd.set_option('future.no_silent_downcasting', True)
from sqlalchemy import create_engine, text
import re
import sys
import json
import argparse
from datetime import datetime
import os
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend for headless environments

# é…ç½®è¾“å‡ºç›®å½•
OUTPUT_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), 'output')
os.makedirs(OUTPUT_DIR, exist_ok=True)

import matplotlib.pyplot as plt
import seaborn as sns
from sqlalchemy.exc import OperationalError as SAOperationalError
from lib.config import Config
import matplotlib.font_manager as fm
from matplotlib.font_manager import FontProperties

# è®¾ç½® matplotlib å’Œ seaborn æ ·å¼ä»¥è·å¾—æ›´å¥½çš„å›¾è¡¨è§†è§‰æ•ˆæœ
sns.set_style("whitegrid")


# Global variable to store CJK font path
_cjk_font_path = None

def get_cjk_font_prop():
    """è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨çš„ç³»ç»Ÿ CJK å­—ä½“çš„ FontPropertiesï¼Œæˆ– Noneã€‚

    è¯¥å‡½æ•°ä¼šå°è¯•å‡ ä¸ªå¸¸è§çš„ç³»ç»Ÿå­—ä½“è·¯å¾„ï¼ˆåŒ…æ‹¬ Noto CJK å’Œ WQYï¼‰ï¼Œå¹¶æ„é€ 
    ä¸€ä¸ª FontProperties æŒ‡å‘è¯¥å­—ä½“æ–‡ä»¶ï¼Œä¾¿äºåœ¨ç»˜å›¾æ—¶æ˜¾å¼ä¼ å…¥ä»¥ä¿è¯ä¸­æ–‡æ˜¾ç¤ºã€‚
    """
    global _cjk_font_path
    candidate_paths = [
        '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
        '/usr/share/fonts/opentype/noto/NotoSerifCJK-Regular.ttc',
        '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
        '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttf',
    ]
    for p in candidate_paths:
        if os.path.exists(p):
            try:
                _cjk_font_path = p
                return FontProperties(fname=p)
            except Exception:
                continue
    # fallback: try to find any system font whose filename hints at CJK
    for p in fm.findSystemFonts(fontpaths=None, fontext='ttf') + fm.findSystemFonts(fontpaths=None, fontext='otf'):
        lp = p.lower()
        if any(k in lp for k in ('noto', 'wqy', 'yahei', 'msyh', 'simhei', 'ukai', 'kaiu')):
            try:
                _cjk_font_path = p
                return FontProperties(fname=p)
            except Exception:
                continue
    return None


# å°è¯•è·å–ä¸€ä¸ª FontPropertiesï¼Œç”¨äºåœ¨ç»˜å›¾æ—¶ä¿è¯ä¸­æ–‡æ–‡æœ¬ä½¿ç”¨å¯ç”¨å­—ä½“
_cjk_prop = get_cjk_font_prop()
if not _cjk_prop:
    print("æ³¨æ„ï¼šæœªæ£€æµ‹åˆ°æ¨èçš„ä¸­æ–‡å­—ä½“ï¼Œå›¾è¡¨ä¸­æ–‡å¯èƒ½æ— æ³•æ­£ç¡®æ˜¾ç¤ºã€‚")
    print("å»ºè®®åœ¨ç³»ç»Ÿä¸Šå®‰è£…å­—ä½“ï¼Œä¾‹å¦‚ (Debian/Ubuntu): sudo apt-get install fonts-noto-cjk fonts-wqy-zenhei")

plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
if _cjk_prop:
    try:
        fam = _cjk_prop.get_name()
        if fam:
            plt.rcParams['font.sans-serif'] = [fam]
            plt.rcParams['font.family'] = 'sans-serif'
    except Exception:
        pass
    # If we have a font file path, monkeypatch font_manager.findfont to always return it
    try:
        if '_cjk_font_path' in globals() and _cjk_font_path:
            # ensure font file is registered with matplotlib's font manager
            try:
                fm.fontManager.addfont(_cjk_font_path)
            except Exception:
                pass
            # after registering, try to set the sans-serif family to the font's family name
            try:
                fam2 = FontProperties(fname=_cjk_font_path).get_name()
                if fam2:
                    plt.rcParams['font.sans-serif'] = [fam2]
                    plt.rcParams['font.family'] = 'sans-serif'
            except Exception:
                pass
            # as a last resort, force findfont to return the font file path
            def _forced_findfont(*args, **kwargs):
                return _cjk_font_path
            fm.findfont = _forced_findfont
    except Exception:
        pass

# =================é…ç½®åŒºåŸŸ=================
# ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ DB_CONNECTION_STRï¼Œå…¶æ¬¡ä» Config.get_db_config() ä¸­è¯»å–å¹¶æ„å»º DSN
# Config.get_db_config() è¿”å›: { 'host','port','database','user','password' }
db_cfg = Config.get_db_config() or {}
env_dsn = os.getenv('DB_CONNECTION_STR')
if env_dsn:
    DB_CONNECTION_STR = env_dsn
else:
    DB_CONNECTION_STR = f"postgresql://{db_cfg.get('user')}:{db_cfg.get('password')}@{db_cfg.get('host')}:{db_cfg.get('port')}/{db_cfg.get('database')}"
# è‹¥ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œåœ¨è¿è¡Œå‰è®¾ç½®: export DB_CONNECTION_STR='postgresql://user:pass@host:5432/db'
# æ‚¨çš„æ¡ˆå­æäº¤ DOJ Memo çš„æ—¥æœŸ (ç”¨äºè®¡ç®—æ‚¨çš„é™é»˜æœŸ)
MY_CASE_MEMO_DATE = '2025-07-30' # ç¤ºä¾‹æ—¥æœŸï¼Œè¯·æ›¿æ¢ä¸ºå®é™…æ—¥æœŸ
# =========================================

# --- æ•°æ®åº“äº¤äº’éƒ¨åˆ† ---

def get_mandamus_data_for_analysis(year=2025):
    """ä»æ•°æ®åº“æ‹‰å–æŒ‡å®šè·¨åº¦ï¼ˆ24ä¸ªæœˆï¼‰çš„ Mandamus æ¡ˆä»¶æ•°æ®"""
    engine = create_engine(DB_CONNECTION_STR)
    
    # æŒ‰ç…§ç”¨æˆ·éœ€æ±‚ï¼Œç»Ÿè®¡æœŸé—´ä» year-1-1 åˆ° (year+1)-12-31 (å…±24ä¸ªæœˆ)
    start_date = f"{year}-01-01"
    end_date = f"{year+1}-12-31"
    
    # æ‹‰å– case_analysis çš„æ ¸å¿ƒæ•°æ®
    # ç­–ç•¥ï¼šæ‹‰å–åœ¨ç»Ÿè®¡æœŸé—´å†…æœ‰ Filing æˆ– Outcome çš„æ‰€æœ‰ Mandamus æ¡ˆä»¶
    query = f"""
    SELECT 
        case_id AS case_number,
        filing_date,
        case_status,
        visa_office,
        time_to_close,
        outcome_date,
        memo_response_time,
        reply_memo_date,
        reply_to_outcome_time
    FROM case_analysis 
    WHERE case_type = 'Mandamus' 
    AND (
        (filing_date >= '{start_date}' AND filing_date <= '{end_date}')
        OR 
        (outcome_date >= '{start_date}' AND outcome_date <= '{end_date}')
    )
    ORDER BY filing_date ASC;
    """
    
    print(f"æ­£åœ¨æå– {year} è‡³ {year+1} å¹´ Mandamus æ¡ˆä»¶æ ¸å¿ƒæ•°æ® (ç»Ÿè®¡æœŸé—´: {start_date} è‡³ {end_date})...")
    try:
        with engine.connect() as connect:
            df = pd.read_sql(text(query), connect)
    except SAOperationalError as e:
        print("æ•°æ®åº“è¿æ¥å¤±è´¥ï¼š", str(e))
        print("è¯·æ£€æŸ¥é…ç½®æˆ–ç¯å¢ƒå˜é‡ DB_CONNECTION_STRï¼Œæˆ–ç¡®ä¿æ•°æ®åº“å‡­æ®åœ¨ Config ä¸­æ­£ç¡®è®¾ç½®ï¼ˆget_db_configï¼‰ã€‚")
        return pd.DataFrame()
    except Exception as e:
        print("è¯»å–æ•°æ®åº“æ—¶å‘ç”Ÿé”™è¯¯ï¼š", str(e))
        return pd.DataFrame()
    
    df['filing_date'] = pd.to_datetime(df['filing_date'], errors='coerce')
    df['outcome_date'] = pd.to_datetime(df['outcome_date'], errors='coerce')
    
    print(f"æå–å®Œæˆ: {len(df)} æ¡è®°å½•")
    return df


def export_cases_to_json(year=2025):
    """æå– Granted å’Œ Dismissed æ¡ˆä»¶çš„åŸå§‹ä¿¡æ¯å’Œåˆ†æç»“æœï¼Œå¹¶ä¿å­˜ä¸º JSONã€‚"""
    engine = create_engine(DB_CONNECTION_STR)
    
    # æŒ‰ç…§ç”¨æˆ·éœ€æ±‚ï¼Œç»Ÿè®¡æœŸé—´ä» year-1-1 åˆ° (year+1)-12-31
    start_date = f"{year}-01-01"
    end_date = f"{year+1}-12-31"

    for status in ['Granted', 'Dismissed']:
        filename_base = f"{status.lower()}_cases_{year}_{year+1}.json"
        filename = os.path.join(OUTPUT_DIR, filename_base)
        print(f"\næ­£åœ¨å¯¼å‡º {status} æ¡ˆä»¶åˆ° {filename}...")
        
        # 1. ä» case_analysis è·å–è¯¥çŠ¶æ€çš„ Mandamus æ¡ˆä»¶ (è·¨åº¦24ä¸ªæœˆ)
        analysis_query = f"""
        SELECT * FROM case_analysis 
        WHERE case_type = 'Mandamus' 
        AND case_status = '{status}'
        AND (
            (filing_date >= '{start_date}' AND filing_date <= '{end_date}')
            OR 
            (outcome_date >= '{start_date}' AND outcome_date <= '{end_date}')
        )
        """
        with engine.connect() as connect:
            analysis_df = pd.read_sql(text(analysis_query), connect)
        
        if analysis_df.empty:
            print(f"   (æœªå‘ç° {year}-{year+1} æœŸé—´ {status} çŠ¶æ€ of Mandamus æ¡ˆä»¶æ•°æ®)")
            continue
            
        case_ids = analysis_df['case_id'].tolist()
        
        # 2. è·å– cases è¡¨çš„åŸå§‹åŸºæœ¬ä¿¡æ¯
        cases_info_list = []
        batch_size = 500
        for i in range(0, len(case_ids), batch_size):
            batch = case_ids[i:i + batch_size]
            batch_str = ",".join([f"'{c}'" for c in batch])
            c_query = f"SELECT * FROM cases WHERE case_number IN ({batch_str})"
            with engine.connect() as connect:
                batch_df = pd.read_sql(text(c_query), connect)
            cases_info_list.append(batch_df)
        
        cases_df = pd.concat(cases_info_list) if cases_info_list else pd.DataFrame()
        
        # 3. è·å–æ‰€æœ‰ç›¸å…³çš„ docket_entries
        docket_list = []
        for i in range(0, len(case_ids), batch_size):
            batch = case_ids[i:i + batch_size]
            batch_str = ",".join([f"'{c}'" for c in batch])
            d_query = f"SELECT * FROM docket_entries WHERE case_number IN ({batch_str}) ORDER BY id_from_table DESC"
            with engine.connect() as connect:
                batch_df = pd.read_sql(text(d_query), connect)
            docket_list.append(batch_df)
            
        docket_df = pd.concat(docket_list) if docket_list else pd.DataFrame()
        
        # 4. ç»„è£…æ•°æ®æ„å»º JSON æ ¼å¼
        json_results = []
        
        # è¾…åŠ©æ—¥æœŸå¤„ç†å‡½æ•°
        def date_handler(obj):
            if hasattr(obj, 'isoformat'):
                return obj.isoformat()
            return obj

        for _, analysis_row in analysis_df.iterrows():
            c_num = analysis_row['case_id']
            
            # è·å–åŸºæœ¬ä¿¡æ¯å­—å…¸
            c_info = cases_df[cases_df['case_number'] == c_num].to_dict('records')
            c_info_dict = c_info[0] if c_info else {}
            
            # è·å–è¯¥æ¡ˆçš„æ‰€æœ‰ docket entries
            entries = docket_df[docket_df['case_number'] == c_num].to_dict('records')
            
            # åˆå¹¶ä¸ºä¸€ä¸ªå¯¹è±¡
            json_results.append({
                "case_number": c_num,
                "analysis_result": {k: date_handler(v) for k, v in analysis_row.to_dict().items()},
                "raw_case_info": {k: date_handler(v) for k, v in c_info_dict.items()},
                "docket_entries": [{k: date_handler(v) for k, v in e.items()} for e in entries]
            })
            
        # ç”Ÿæˆ summaryï¼Œå†™å…¥æ–‡ä»¶ï¼ˆsummary åœ¨æ–‡ä»¶å¼€å§‹éƒ¨åˆ†ï¼‰
        try:
            # è®¡ç®— summary æŒ‡æ ‡
            total_cases = len(json_results)
            case_number_list = ",".join([str(r.get('case_number') or '') for r in json_results])

            # ä½¿ç”¨ analysis_df ä¸­çš„æ•°å€¼åˆ—è®¡ç®—å¹³å‡å€¼ï¼ˆæ›´å¯é ï¼‰
            age_avg = None
            reply_to_outcome_avg = None
            try:
                if 'age_of_case' in analysis_df.columns:
                    age_avg_val = pd.to_numeric(analysis_df['age_of_case'], errors='coerce')
                    if age_avg_val.notna().any():
                        age_avg = float(round(age_avg_val.mean(), 1))
                if 'reply_to_outcome_time' in analysis_df.columns:
                    rto_val = pd.to_numeric(analysis_df['reply_to_outcome_time'], errors='coerce')
                    if rto_val.notna().any():
                        reply_to_outcome_avg = float(round(rto_val.mean(), 1))
            except Exception:
                age_avg = None
                reply_to_outcome_avg = None

            summary = {
                'total_cases': total_cases,
                'case_number_list': case_number_list,
                'age_of_case_avg': age_avg,
                'reply_to_outcome_time_avg': reply_to_outcome_avg
            }

            out_obj = {'summary': summary, 'cases': json_results}
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(out_obj, f, ensure_ascii=False, indent=2)
            print(f"âœ… å·²æˆåŠŸç”Ÿæˆ {filename} (å« {len(json_results)} ä¸ªæ¡ˆä»¶)ï¼Œå¹¶åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ  summary")
        except Exception as e:
            print(f"âŒ å†™å…¥ {filename} å¤±è´¥: {e}")

# --- åˆ†æå’Œå¯è§†åŒ–éƒ¨åˆ† ---

def plot_workload_trends(df_monthly, year=2025):
    """ç»˜åˆ¶æ¯æœˆæ³¨å†Œé‡ã€ç»“æ¡ˆé‡å’Œå‡€ç§¯å‹å˜åŒ–è¶‹åŠ¿å›¾"""

    fig, ax1 = plt.subplots(figsize=(12, 6))

    # ç»˜åˆ¶æ³¨å†Œé‡ (Filing Count)
    ax1.plot(df_monthly.index, df_monthly['filing_count'], marker='o', linestyle='-', color='tab:blue', label='æ¡ˆä»¶æ³¨å†Œé‡')
    if _cjk_prop:
        ax1.set_xlabel('æœˆä»½', fontproperties=_cjk_prop)
        ax1.set_ylabel('æ¡ˆä»¶æ•°é‡', color='tab:blue', fontproperties=_cjk_prop)
    else:
        ax1.set_xlabel('æœˆä»½')
        ax1.set_ylabel('æ¡ˆä»¶æ•°é‡', color='tab:blue')
    ax1.tick_params(axis='y', labelcolor='tab:blue')

    # ç¬¬äºŒä¸ªYè½´ç»˜åˆ¶å‡€ç§¯å‹å˜åŒ– (Net Change)
    ax2 = ax1.twinx() 
    ax2.bar(df_monthly.index, df_monthly['net_change'], width=20, alpha=0.6, color=np.where(df_monthly['net_change'] >= 0, 'tab:red', 'tab:green'), label='å‡€ç§¯å‹å˜åŒ–')
    if _cjk_prop:
        ax2.set_ylabel('å‡€ç§¯å‹å˜åŒ– (æ³¨å†Œ - ç»“æ¡ˆ)', color='tab:red', fontproperties=_cjk_prop)
    else:
        ax2.set_ylabel('å‡€ç§¯å‹å˜åŒ– (æ³¨å†Œ - ç»“æ¡ˆ)', color='tab:red')
    ax2.tick_params(axis='y', labelcolor='tab:red')

    fig.autofmt_xdate(rotation=45)
    title_str = f'{year}-{year+1} å¹´ Mandamus æ¡ˆä»¶æ¯æœˆè´Ÿè·åŠç§¯å‹è¶‹åŠ¿'
    if _cjk_prop:
        ax1.set_title(title_str, fontproperties=_cjk_prop)
        leg = ax1.legend(loc='upper left', prop=_cjk_prop)
    else:
        plt.title(title_str)
        leg = ax1.legend(loc='upper left')
    # ensure x tick labels use CJK font if available
    if _cjk_prop:
        for lbl in ax1.get_xticklabels():
            lbl.set_fontproperties(_cjk_prop)
    save_path = os.path.join(OUTPUT_DIR, f'mandamus_workload_trends_{year}.png')
    plt.savefig(save_path)
    print(f"ğŸ“ˆ å·²ä¿å­˜è´Ÿè½½è¶‹åŠ¿å›¾è‡³: {save_path}")
    plt.close()


def plot_outcome_trends(df_monthly, year=2025):
    """ç»˜åˆ¶æ¯æœˆç»“æ¡ˆæ–¹å¼è¶‹åŠ¿å›¾"""

    # å †å å›¾æ•°æ®å‡†å¤‡ï¼šåªçœ‹å·²ç»“æ¡ˆçš„éƒ¨åˆ†
    df_outcome_plot = df_monthly[['settled_count', 'dismissed_count', 'granted_count']].fillna(0)

    # å°†å…¶ä»–æ–¹å¼ç»“æ¡ˆåˆå¹¶ä¸º "Other/Dismissed"
    df_outcome_plot['Other/Dismissed'] = df_outcome_plot['dismissed_count'] # å‡è®¾è´¥è¯‰å æ¯”æœ€å¤š
    df_outcome_plot['Settled'] = df_outcome_plot['settled_count']
    df_outcome_plot['Granted'] = df_outcome_plot['granted_count']

    fig, ax = plt.subplots(figsize=(12, 6))
    df_outcome_plot[['Settled', 'Granted', 'Other/Dismissed']].plot(kind='bar', stacked=True, ax=ax)

    title_str = f'{year}-{year+1} å¹´ Mandamus æ¡ˆä»¶æ¯æœˆç»“æ¡ˆæ–¹å¼åˆ†å¸ƒ'
    if _cjk_prop:
        ax.set_title(title_str, fontproperties=_cjk_prop)
        ax.set_xlabel('æœˆä»½', fontproperties=_cjk_prop)
        ax.set_ylabel('ç»“æ¡ˆæ•°é‡', fontproperties=_cjk_prop)
        leg = ax.legend(title='ç»“æ¡ˆæ–¹å¼', prop=_cjk_prop)
        for lbl in ax.get_xticklabels():
            lbl.set_fontproperties(_cjk_prop)
        if leg:
            for text in leg.get_texts():
                text.set_fontproperties(_cjk_prop)
    else:
        ax.set_title(title_str)
        ax.set_xlabel('æœˆä»½')
        ax.set_ylabel('ç»“æ¡ˆæ•°é‡')
        plt.legend(title='ç»“æ¡ˆæ–¹å¼')
    fig.autofmt_xdate(rotation=45)
    save_path = os.path.join(OUTPUT_DIR, f'mandamus_outcome_trends_{year}.png')
    plt.savefig(save_path)
    print(f"ğŸ“ˆ å·²ä¿å­˜ç»“æ¡ˆæ–¹å¼è¶‹åŠ¿å›¾è‡³: {save_path}")
    plt.close()


def plot_timeline_trends(df_monthly, year=2025):
    """ç»˜åˆ¶æ¯æœˆç»“æ¡ˆè€—æ—¶è¶‹åŠ¿å›¾"""

    fig, ax = plt.subplots(figsize=(12, 6))

    # ç»˜åˆ¶å¹³å‡ç»“æ¡ˆè€—æ—¶ (ä¸­ä½æ•°)
    ax.plot(df_monthly.index, df_monthly['median_time_to_close'], marker='s', linestyle='--', color='purple', label='ä¸­ä½æ•°æ€»è€—æ—¶')

    title_str = f'{year}-{year+1} å¹´ Mandamus æ¡ˆä»¶ä¸­ä½æ•°ç»“æ¡ˆè€—æ—¶è¶‹åŠ¿'
    if _cjk_prop:
        ax.set_title(title_str, fontproperties=_cjk_prop)
        ax.set_xlabel('æœˆä»½', fontproperties=_cjk_prop)
        ax.set_ylabel('è€—æ—¶ (å¤©æ•°)', fontproperties=_cjk_prop)
    else:
        ax.set_title(title_str)
        ax.set_xlabel('æœˆä»½')
        ax.set_ylabel('è€—æ—¶ (å¤©æ•°)')

    fig.autofmt_xdate(rotation=45)
    plt.legend()
    save_path = os.path.join(OUTPUT_DIR, f'mandamus_timeline_trends_{year}.png')
    plt.savefig(save_path)
    print(f"ğŸ“ˆ å·²ä¿å­˜ç»“æ¡ˆè€—æ—¶è¶‹åŠ¿å›¾è‡³: {save_path}")
    plt.close()


def plot_memo_response_trends(df_monthly, year=2025):
    """ç»˜åˆ¶æ¯æœˆ DOJ Memo å“åº”æ—¶é—´è¶‹åŠ¿å›¾"""
    # Memo response trends feature removed per user request.
    return


def plot_memo_reply_to_outcome_trends(df, year=2025):
    """æŒ‰æœˆç»Ÿè®¡ï¼šä» memo å›å¤åˆ°ç»“æ¡ˆçš„æ—¶é—´ï¼ˆå¤©ï¼‰ï¼ŒæŒ‰ç»“æ¡ˆç±»å‹åˆ†ç³»åˆ—ç»˜å›¾ã€‚
    
    ç»Ÿè®¡ 24 ä¸ªæœˆçš„è·¨åº¦ (YEAR è‡³ YEAR+1)ã€‚
    """
    df = df.copy()
    # å¿…è¦å­—æ®µ - åŒ…å« reply_memo_date
    required_fields = {'filing_date', 'outcome_date', 'case_status', 'case_number', 'reply_memo_date'}
    
    if not required_fields.issubset(df.columns):
        print(f"ç¼ºå°‘å¿…è¦å­—æ®µï¼Œè·³è¿‡ reply_memo->outcome ç»Ÿè®¡ã€‚éœ€è¦ï¼š{required_fields - set(df.columns)}")
        return

    # æå–å‚è€ƒæ¡ˆä¾‹çš„ä¿¡æ¯ä½œä¸ºå‚è€ƒ
    reference_days = None
    target_case_num = f'IMM-11243-{year % 100:02d}' # å°è¯•åŒ¹é…å½“å‰å¹´ä»½çš„å‚è€ƒæ¡ˆ
    target_case = df[df['case_number'] == target_case_num]
    if target_case.empty:
        # å°è¯•é»˜è®¤æ¡ˆå·
        target_case = df[df['case_number'] == 'IMM-11243-25']
        
    if not target_case.empty:
        case_row = target_case.iloc[0]
        if pd.notna(case_row['reply_memo_date']):
            reference_start_date = pd.to_datetime(case_row['reply_memo_date'])
        else:
            reference_start_date = pd.to_datetime(f'{year}-07-30') # å¤‡é€‰
        
        if reference_start_date is not None:
            if pd.notna(case_row['outcome_date']):
                end_date = pd.to_datetime(case_row['outcome_date'])
                period_desc = f"è‡³ç»“æ¡ˆæ—¥æœŸ {end_date.date()}"
            else:
                end_date = pd.Timestamp.now()
                period_desc = f"è‡³ä»Šå¤© {end_date.date()}"
            
            reference_days = (end_date - reference_start_date).days
            print(f"å‚è€ƒæ¡ˆä¾‹ {case_row['case_number']}: memoå›å¤æ—¥æœŸ={reference_start_date.date()}, {period_desc}, å¤©æ•°={reference_days:.0f}å¤©")

    # è½¬æ¢æ—¥æœŸå­—æ®µå¹¶è®¡ç®— reply_to_outcome_days
    df['filing_date'] = pd.to_datetime(df['filing_date'], errors='coerce')
    df['outcome_date'] = pd.to_datetime(df['outcome_date'], errors='coerce')
    df['reply_memo_date'] = pd.to_datetime(df['reply_memo_date'], errors='coerce')
    
    df['calculated_reply_date'] = df['reply_memo_date']
    mask_need_calc = df['calculated_reply_date'].isna() & df['memo_response_time'].notna() & df['filing_date'].notna()
    if mask_need_calc.any():
        df.loc[mask_need_calc, 'calculated_reply_date'] = df.loc[mask_need_calc, 'filing_date'] + pd.to_timedelta(df.loc[mask_need_calc, 'memo_response_time'], unit='D')

    df['reply_to_outcome_days'] = None
    resolved_mask = df['case_status'].isin(['Discontinued', 'Granted', 'Dismissed'])
    resolved_with_dates = resolved_mask & df['outcome_date'].notna() & df['calculated_reply_date'].notna()
    
    if resolved_with_dates.any():
        df.loc[resolved_with_dates, 'reply_to_outcome_days'] = (
            df.loc[resolved_with_dates, 'outcome_date'] - df.loc[resolved_with_dates, 'calculated_reply_date']
        ).dt.days

    df_valid = df[df['reply_to_outcome_days'].notna() & (df['reply_to_outcome_days'] >= 0)].copy()
    if df_valid.empty:
        print("æ²¡æœ‰æœ‰æ•ˆçš„ reply_memo åˆ° outcome æ—¶é—´æ•°æ®ï¼Œè·³è¿‡ç»˜å›¾ã€‚")
        return

    df_resolved = df_valid[df_valid['case_status'].isin(['Discontinued', 'Granted', 'Dismissed'])].copy()
    if df_resolved.empty:
        print("æ²¡æœ‰å·²ç»“æ¡ˆçš„æœ‰æ•ˆæ•°æ®ç”¨äºæœˆåº¦è¶‹åŠ¿ï¼Œè·³è¿‡ç»˜å›¾ã€‚")
        return

    # é™åˆ¶åœ¨ç»Ÿè®¡æœŸå†…ï¼Œä¸”ä¸è¶…è¿‡ä»Šå¤©
    period_start = f"{year}-01-01"
    today = pd.Timestamp.now()
    period_end = min(pd.Timestamp(f"{year+1}-12-31"), today)
    
    df_resolved = df_resolved[(df_resolved['outcome_date'] >= period_start) & (df_resolved['outcome_date'] <= period_end)]
    
    if df_resolved.empty:
        period_end_str = period_end.strftime('%Y-%m-%d')
        print(f"åœ¨ {year}-01-01 è‡³ {period_end_str} æœŸé—´æ²¡æœ‰å·²ç»“æ¡ˆçš„æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡ç»˜å›¾ã€‚")
        return

    grouped = df_resolved.groupby([pd.Grouper(key='outcome_date', freq='ME'), 'case_status'])['reply_to_outcome_days'].agg(['mean', 'median'])
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    metrics = [('mean', 'å¹³å‡å€¼'), ('median', 'ä¸­ä½æ•°')]
    axes = [ax1, ax2]
    
    for (metric, metric_name), ax in zip(metrics, axes):
        pivot_data = grouped[metric].unstack(level=-1)
        for col in pivot_data.columns:
            ax.plot(pivot_data.index, pivot_data[col], marker='o', linestyle='-', label=str(col))
        
        if reference_days is not None:
            ref_label = f"å‚è€ƒæ¡ˆ ({reference_days:.0f}å¤©)"
            ax.axhline(y=reference_days, color='red', linestyle='--', linewidth=2, label=ref_label)
            if _cjk_prop:
                ax.legend(prop=_cjk_prop)
            else:
                ax.legend()
        
        if _cjk_prop:
            ax.set_title(f'{year}-{year+1} Memoå›å¤åˆ°ç»“æ¡ˆæ—¶é—´ - {metric_name}ï¼ˆå¤©ï¼‰', fontproperties=_cjk_prop)
            ax.set_xlabel('ç»“æ¡ˆæœˆä»½', fontproperties=_cjk_prop)
            ax.set_ylabel('å¤©æ•°', fontproperties=_cjk_prop)
        else:
            ax.set_title(f'{year}-{year+1} Memo Reply to Outcome Time - {metric_name} (days)')
            ax.set_xlabel('Outcome Month')
            ax.set_ylabel('Days')
        ax.tick_params(axis='x', rotation=45)

    title_main = f'{year}-{year+1} æŒ‰ç»“æ¡ˆç±»å‹ç»Ÿè®¡ï¼šMemoå›å¤åˆ°ç»“æ¡ˆæ—¶é—´åˆ†æ'
    fig.suptitle(title_main, fontsize=16, fontproperties=_cjk_prop if _cjk_prop else None)
    fig.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, f'mandamus_memo_to_outcome_trends_{year}.png')
    plt.savefig(save_path)
    print(f"ğŸ“ˆ å·²ä¿å­˜ Memo åˆ°ç»“æ¡ˆæ—¶é—´ç»Ÿè®¡å›¾è‡³: {save_path}")
    plt.close()

    # === æ‰“å°æ‘˜è¦ç»Ÿè®¡å†…å®¹ ===
    print("\n" + "="*60)
    print(f"ã€Memoå›å¤åˆ°ç»“æ¡ˆæ—¶é—´åˆ†ææ‘˜è¦ ({year}-{year+1})ã€‘")
    print("="*60)
    
    summary_overall = df_resolved.groupby(pd.Grouper(key='outcome_date', freq='ME'))['reply_to_outcome_days'].agg(['count', 'mean']).rename(columns={'count': 'resolved_count', 'mean': 'avg_days'})
    print(f"\n--- æ¯æœˆæ€»ä½“ç»“æ¡ˆç»Ÿè®¡ ({year}-{year+1}) ---")
    if not summary_overall.empty:
        summary_overall.index = summary_overall.index.strftime('%Y-%m')
        summary_overall['avg_days'] = summary_overall['avg_days'].astype(float).round(1)
        print(summary_overall) # æ‰“å°å…¨éƒ¨
    else:
        print("   (æ— æ•°æ®)")

    monthly_status_agg = df_resolved.groupby([pd.Grouper(key='outcome_date', freq='ME'), 'case_status'])['reply_to_outcome_days'].agg(['count', 'mean'])
    
    # æ„å»ºå±•ç¤ºç”¨çš„ç´¢å¼•ï¼šä» period_start åˆ° period_end
    # ä½¿ç”¨ freq='ME'ï¼Œä½†ç¡®ä¿å¦‚æœä»Šå¤©è¿˜åœ¨æœˆä¸­ï¼Œä¹Ÿèƒ½æ˜¾ç¤ºå½“å‰æœˆ
    idx_range = pd.date_range(start=period_start, end=period_end + pd.offsets.MonthEnd(0), freq='ME')
    idx = idx_range[idx_range <= period_end + pd.offsets.MonthEnd(0)].strftime('%Y-%m')
    status_summary = pd.DataFrame(index=idx)
    
    found_any = False
    for status in ['Granted', 'Dismissed']:
        if status in monthly_status_agg.index.get_level_values('case_status'):
            s_data = monthly_status_agg.xs(status, level='case_status')
            s_data.index = s_data.index.strftime('%Y-%m')
            status_summary[f'{status}_cnt'] = s_data['count']
            status_summary[f'{status}_avg(days)'] = s_data['mean']
            found_any = True
    
    print(f"\n--- æ¯æœˆåˆ†ç±»ç»“æ¡ˆç»Ÿè®¡ (Granted/Dismissed) ({year}-{year+1}) ---")
    if found_any:
        cols = [c for c in status_summary.columns if status_summary[c].notna().any()]
        if cols:
            for col in cols:
                if '_cnt' in col:
                    status_summary[col] = status_summary[col].fillna(0).astype(int)
                else:
                    status_summary[col] = status_summary[col].fillna(0).astype(float).round(1)
            print(status_summary[cols]) # æ‰“å°å…¨éƒ¨
        else:
            print("   (æ— æ•°æ®)")
    else:
        print("   (æœªå‘ç° Granted æˆ– Dismissed æ¡ˆä¾‹æ•°æ®)")

    total_count = len(df_resolved)
    avg_duration = df_resolved['reply_to_outcome_days'].mean()
    print(f"\nã€æ€»ä½“æ±‡æ€»ã€‘ ç»“æ¡ˆæ€»æ•°: {total_count} | æ€»ä½“å¹³å‡è€—æ—¶: {avg_duration:.1f} å¤©")
    print("=" * 60)


def plot_case_duration_distribution(df, year=2025):
    """ç»˜åˆ¶ç»“æ¡ˆè€—æ—¶åˆ†å¸ƒç›´æ–¹å›¾"""
    # ä»…ç»Ÿè®¡å·²ç»“æ¡ˆä¸”æœ‰è€—æ—¶æ•°æ®çš„ Mandamus æ¡ˆä»¶
    df_resolved = df[df['case_status'].isin(['Discontinued', 'Granted', 'Dismissed'])].copy()
    if df_resolved.empty or 'time_to_close' not in df_resolved.columns or df_resolved['time_to_close'].isna().all():
        return

    durations = df_resolved['time_to_close'].dropna()
    
    plt.figure(figsize=(12, 6))
    
    # è‡ªåŠ¨ç¡®å®š bin æ•°é‡
    sns.histplot(durations, bins=min(30, len(durations.unique())), kde=True, color='teal', alpha=0.6)
    
    # æ·»åŠ ä¸­ä½æ•°çº¿
    median_val = durations.median()
    plt.axvline(median_val, color='red', linestyle='--', linewidth=2, label=f'ä¸­ä½æ•°: {median_val:.1f}å¤©')
    
    title = f'Mandamus æ¡ˆä»¶ç»“æ¡ˆæ—¶é•¿åˆ†å¸ƒ ({year}-{year+1})'
    xlabel = 'ç»“æ¡ˆè€—æ—¶ (å¤©)'
    ylabel = 'æ¡ˆä»¶æ•°é‡'
    
    if _cjk_prop:
        plt.title(title, fontproperties=_cjk_prop, fontsize=16)
        plt.xlabel(xlabel, fontproperties=_cjk_prop)
        plt.ylabel(ylabel, fontproperties=_cjk_prop)
        plt.legend(prop=_cjk_prop)
    else:
        plt.title(title, fontsize=16)
        plt.xlabel(xlabel)
        plt.ylabel(ylabel)
        plt.legend()
        
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, f'mandamus_duration_distribution_{year}.png')
    plt.savefig(save_path)
    print(f"ğŸ“ˆ å·²ä¿å­˜ç»“æ¡ˆè€—æ—¶åˆ†å¸ƒå›¾è‡³: {save_path}")
    plt.close()


def analyze_resolution_time_distribution(df):
    """ç»Ÿè®¡ä¸åŒç»“æ¡ˆæ—¶é•¿ (age_of_case at resolution) çš„æ¡ˆä»¶åˆ†å¸ƒ"""
    # ç­›é€‰å·²ç»“æ¡ˆçš„æ¡ˆä»¶
    df_resolved = df[df['case_status'].isin(['Discontinued', 'Granted', 'Dismissed'])].copy()
    
    if df_resolved.empty or 'time_to_close' not in df_resolved.columns or df_resolved['time_to_close'].isna().all():
        print("\n--- ç»“æ¡ˆè€—æ—¶åˆ†å¸ƒç»Ÿè®¡ ---")
        print("   (æ²¡æœ‰æœ‰æ•ˆçš„ç»“æ¡ˆè€—æ—¶æ•°æ®)")
        return

    # time_to_close å³ä¸ºç»“æ¡ˆæ—¶çš„ age_of_case
    durations = df_resolved['time_to_close'].dropna()
    
    print("\n--- ç»“æ¡ˆè€—æ—¶åˆ†å¸ƒç»Ÿè®¡ (Mandamus) ---")
    
    # å®šä¹‰åŒºé—´ (0, 30, 60, ..., 240, 365, +inf)
    bins = [0, 30, 60, 90, 120, 150, 180, 210, 240, 365, float('inf')]
    labels = ['0-30å¤©', '31-60å¤©', '61-90å¤©', '91-120å¤©', '121-150å¤©', '151-180å¤©', '181-210å¤©', '211-240å¤©', '241-365å¤©', '365å¤©ä»¥ä¸Š']
    
    # ç»Ÿè®¡
    dist = pd.cut(durations, bins=bins, labels=labels, right=True).value_counts().sort_index()
    total = len(durations)
    
    for label, count in dist.items():
        percentage = (count / total) * 100 if total > 0 else 0
        print(f"   {label:12}: {count:>4} æ¡ˆ ({percentage:>4.1f}%)")
    
    # æ‰¾å‡ºå¤šæ•°æ¡ˆä»¶æ‰€åœ¨èŒƒå›´
    if total > 0:
        most_common_range = dist.idxmax()
        print(f"\nğŸ“Š ç»“è®º: å¤šæ•° Mandamus æ¡ˆä»¶åœ¨ {most_common_range} èŒƒå›´å†…ç»“æ¡ˆã€‚")
    print("-" * 50)


def run_monthly_analysis(df, year=2025):
    """
    å®ç°æŒ‰æœˆç»Ÿè®¡çš„é€»è¾‘ï¼Œå¥å£®å¤„ç†æ²¡æœ‰æ—¥æœŸæˆ–å…¨éƒ¨ä¸º NaT çš„æƒ…å†µã€‚
    """

    df = df.copy()
    df['filing_date'] = pd.to_datetime(df.get('filing_date'), errors='coerce')
    df['outcome_date'] = pd.to_datetime(df.get('outcome_date'), errors='coerce')

    # å¦‚æœæ—¢æ²¡æœ‰ filing_date ä¹Ÿæ²¡æœ‰ outcome_dateï¼Œåˆ™æ— æ³•åšæŒ‰æœˆåˆ†æ
    if not (df['filing_date'].notna().any() or df['outcome_date'].notna().any()):
        print("æ— æœ‰æ•ˆæ—¥æœŸæ•°æ®ï¼Œæ— æ³•è¿›è¡ŒæŒ‰æœˆåˆ†æã€‚")
        return

    # æŒ‰ filing_date (æ³¨å†Œæ—¥æœŸ) ç»Ÿè®¡æ¯æœˆæ³¨å†Œé‡
    if df['filing_date'].notna().any():
        df_filed_monthly = df.groupby(pd.Grouper(key='filing_date', freq='ME'))['case_number'].count().rename('filing_count')
    else:
        df_filed_monthly = pd.Series(dtype='int64', name='filing_count')

    # æŒ‰ outcome_date (ç»“æ¡ˆæ—¥æœŸ) ç»Ÿè®¡æ¯æœˆç»“æ¡ˆé‡
    df_resolved = df[df['case_status'].isin(['Discontinued', 'Granted', 'Dismissed'])]
    if (not df_resolved.empty) and df_resolved['outcome_date'].notna().any():
        df_resolved_monthly = df_resolved.groupby(pd.Grouper(key='outcome_date', freq='ME'))['case_number'].count().rename('resolution_count')
    else:
        df_resolved_monthly = pd.Series(dtype='int64', name='resolution_count')

    # åˆå¹¶æ•°æ®å¹¶è®¡ç®—å‡€ç§¯å‹å˜åŒ–
    df_monthly = pd.concat([df_filed_monthly, df_resolved_monthly], axis=1).fillna(0)
    df_monthly['net_change'] = df_monthly['filing_count'] - df_monthly['resolution_count']

    # ç»“æ¡ˆæ–¹å¼è¶‹åŠ¿
    def _safe_group(res_df, status, col='outcome_date'):
        if res_df.empty or res_df[col].notna().sum() == 0:
            return pd.Series(dtype='int64')
        return res_df[res_df['case_status'] == status].groupby(pd.Grouper(key=col, freq='ME'))['case_number'].count().rename(f"{status.lower()}_count")

    df_monthly['settled_count'] = _safe_group(df_resolved, 'Discontinued')
    df_monthly['granted_count'] = _safe_group(df_resolved, 'Granted')
    df_monthly['dismissed_count'] = _safe_group(df_resolved, 'Dismissed')

    # å…³é”®è€—æ—¶è¶‹åŠ¿ (ä¸­ä½æ•°)
    if (not df_resolved.empty) and df_resolved['outcome_date'].notna().any() and df_resolved['time_to_close'].notna().any():
        df_time_to_close_monthly = df_resolved.groupby(pd.Grouper(key='outcome_date', freq='ME'))['time_to_close'].median().rename('median_time_to_close')
        df_monthly = pd.concat([df_monthly, df_time_to_close_monthly], axis=1)
    else:
        df_monthly['median_time_to_close'] = np.nan
    
    # Memo å“åº”æ—¶é—´è¶‹åŠ¿
    df_with_memo = df[df['memo_response_time'].notna()]
    if not df_with_memo.empty:
        df_memo_monthly = df_with_memo.groupby(pd.Grouper(key='filing_date', freq='ME'))['memo_response_time'].median().rename('median_memo_response_time')
        df_monthly = pd.concat([df_monthly, df_memo_monthly], axis=1)
    else:
        df_monthly['median_memo_response_time'] = np.nan

    if df_monthly.empty:
        print("æ²¡æœ‰ç”Ÿæˆä»»ä½•æŒ‰æœˆç»Ÿè®¡æ•°æ®ã€‚")
        return

    # é™åˆ¶ç»Ÿè®¡å±•ç¤ºèŒƒå›´ä¸º 24 ä¸ªæœˆï¼Œä¸”æœ€å¤§ä¸è¶…è¿‡ä»Šå¤©
    period_start = f"{year}-01-01"
    today = pd.Timestamp.now()
    period_end = min(pd.Timestamp(f"{year+1}-12-31"), today)
    
    # å¡«å……ç¼ºå¤±æœˆä»½ä»¥ç¡®ä¿å±•ç¤ºï¼Œä½†ä¸Šé™ä¸ºä»Šå¤©æ‰€åœ¨çš„æœˆä»½
    # ä½¿ç”¨ freq='ME' é…åˆ period_end çš„ offsets å¤„ç†ï¼Œç¡®ä¿åŒ…å«å½“å‰æœˆ
    full_idx = pd.date_range(start=period_start, end=period_end + pd.offsets.MonthEnd(0), freq='ME')
    df_monthly = df_monthly.reindex(full_idx).fillna(0)

    # ç»˜åˆ¶è¶‹åŠ¿å›¾è¡¨
    plot_workload_trends(df_monthly, year)
    plot_outcome_trends(df_monthly, year)
    plot_timeline_trends(df_monthly, year)
    plot_memo_response_trends(df_monthly, year)
    
    # å‡†å¤‡ä»…é™æœ¬ç»Ÿè®¡å‘¨æœŸå†…ç»“æ¡ˆçš„æ•°æ®ï¼Œç”¨äºåˆ†å¸ƒåˆ†æ
    df_resolved_in_period = df_resolved[(df_resolved['outcome_date'] >= period_start) & (df_resolved['outcome_date'] <= period_end)].copy()

    # Memo reply->outcome plotting removed per user request.

    # ç»“æ¡ˆè€—æ—¶åˆ†å¸ƒåˆ†æ (ä»…é™æœ¬å‘¨æœŸå†…ç»“æ¡ˆçš„æ¡ˆå­)
    try:
        plot_case_duration_distribution(df_resolved_in_period, year)
    except Exception as e:
        print('ç»˜åˆ¶ç»“æ¡ˆæ—¶é•¿åˆ†å¸ƒå›¾å¤±è´¥ï¼š', e)

    # æ‰“å°æ–‡å­—æŠ¥å‘Š
    print("\n" + "="*50)
    print(f"ã€{year}-{year+1} å¹´æŒ‰æœˆç»Ÿè®¡è¶‹åŠ¿åˆ†ææŠ¥å‘Šã€‘")
    print("="*50)
    print(f"\n--- æ¡ˆä»¶è´Ÿè·ä¸ç§¯å‹å˜åŒ– ({year}-{year+1}) ---")
    print(df_monthly[['filing_count', 'resolution_count', 'net_change']].round(0).astype(int))

    # æ–‡å­—ç‰ˆåˆ†å¸ƒç»Ÿè®¡ (ä»…é™æœ¬å‘¨æœŸå†…ç»“æ¡ˆçš„æ¡ˆå­)
    analyze_resolution_time_distribution(df_resolved_in_period)

    print(f"\n--- ç»“æ¡ˆæ–¹å¼ç™¾åˆ†æ¯” ({year}-{year+1}) ---")
    df_report = df_monthly.copy()
    df_report['resolution_total'] = df_report[['settled_count', 'granted_count', 'dismissed_count']].sum(axis=1).fillna(0)
    # convert to int for display counts
    df_report['resolution_total'] = df_report['resolution_total'].astype(int)

    def _count_pct_str(row, col_name):
        total = row['resolution_total']
        try:
            cnt = int(row.get(col_name, 0) if not pd.isna(row.get(col_name, 0)) else 0)
        except Exception:
            cnt = 0
        pct = (cnt / total * 100) if total > 0 else 0.0
        return f"{cnt}|{pct:.1f}%"

    df_report['Settled|Rate'] = df_report.apply(lambda r: _count_pct_str(r, 'settled_count'), axis=1)
    df_report['Granted|Rate'] = df_report.apply(lambda r: _count_pct_str(r, 'granted_count'), axis=1)
    df_report['Dismiss|Rate'] = df_report.apply(lambda r: _count_pct_str(r, 'dismissed_count'), axis=1)

    # å¯¹ä¸­ä½æ•°è€—æ—¶è¿›è¡Œå››èˆäº”å…¥
    df_report['median_time_to_close'] = df_report['median_time_to_close'].round(1)
    df_report.index = df_report.index.strftime('%Y-%m')
    print(df_report[['resolution_total', 'Settled|Rate', 'Granted|Rate', 'Dismiss|Rate', 'median_time_to_close']])
    
    # DOJ Memo response reporting removed per user request.

    print("\nã€è¶‹åŠ¿è§£è¯»ã€‘")
    # æ£€æŸ¥æœ€è¿‘ä¸‰ä¸ªæœˆçš„å‡€ç§¯å‹å˜åŒ–
    recent_change = df_monthly['net_change'].tail(3).mean()
    # æ£€æŸ¥æœ€è¿‘ä¸‰ä¸ªæœˆçš„ä¸­ä½æ•°ç»“æ¡ˆæ—¶é—´æ˜¯å¦æ¯”ä¹‹å‰ä¸‰ä¸ªæœˆæœ‰æ‰€å¢åŠ 
    # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œæ¯”è¾ƒ
    if len(df_monthly) >= 6:
        recent_median_time = df_monthly['median_time_to_close'].tail(3).mean()
        previous_median_time = df_monthly['median_time_to_close'].iloc[-6:-3].mean()
    else: # å¦‚æœæ•°æ®ä¸è¶³6ä¸ªæœˆï¼Œåˆ™æ— æ³•è¿›è¡Œæœ‰æ„ä¹‰çš„è¶‹åŠ¿æ¯”è¾ƒ
        recent_median_time = np.nan
        previous_median_time = np.nan

    if recent_change > 0:
        print("-> ğŸš¨ è­¦å‘Šï¼šè¿‘æœŸå‡€ç§¯å‹å˜åŒ–å¹³å‡ä¸ºæ­£å€¼ï¼Œæ³•é™¢/IRCC æ­£åœ¨æ‰¿å—æ›´å¤§å‹åŠ›ï¼Œæœªæ¥æ¡ˆä»¶å¤„ç†é€Ÿåº¦å¯èƒ½ä¼šå‡æ…¢ã€‚")
    elif not np.isnan(recent_median_time) and not np.isnan(previous_median_time) and recent_median_time > previous_median_time:
        print("-> âš ï¸ æ³¨æ„ï¼šå°½ç®¡ç§¯å‹å˜åŒ–ä¸æ˜æ˜¾ï¼Œä½†ç»“æ¡ˆæ‰€éœ€çš„ä¸­ä½æ•°æ—¶é—´ä»åœ¨å¢åŠ ï¼Œè¡¨æ˜æ•ˆç‡æœ‰æ‰€ä¸‹é™ã€‚")
    else:
        print("-> âœ… ç¨³å®šï¼šç›®å‰æ¡ˆä»¶ç§¯å‹è¶‹åŠ¿å’Œç»“æ¡ˆè€—æ—¶è¾ƒä¸ºç¨³å®šã€‚")



# --- ä¸»æ‰§è¡ŒåŒº ---
def main():
    parser = argparse.ArgumentParser(description='FCT Mandamus æ¡ˆä»¶åˆ†æä¸æ•°æ®å¯¼å‡º')
    parser.add_argument('--year', type=int, default=2025, help='è¦åˆ†æå’Œå¯¼å‡ºçš„èµ·å§‹å¹´ä»½ (ç»Ÿè®¡è·¨åº¦ä¸º YEAR è‡³ YEAR+1)')
    args = parser.parse_args()
    
    target_year = args.year
    
    # 1. æå–æ ¸å¿ƒæ•°æ®
    df_core = get_mandamus_data_for_analysis(target_year)
    
    # 2. è¿è¡ŒæŒ‰æœˆåˆ†æå¹¶ç»˜åˆ¶å›¾è¡¨
    if not df_core.empty:
        run_monthly_analysis(df_core, target_year)
        
        # 3. é¢å¤–åŠŸèƒ½ï¼šå¯¼å‡ºè¯¦ç»†ä¿¡æ¯ä¸º JSON
        export_cases_to_json(target_year)
    else:
        print(f"æœªæ‰¾åˆ° {target_year}-{target_year+1} æœŸé—´ Mandamus æ¡ˆä»¶æ•°æ®è¿›è¡Œåˆ†æã€‚")

####################################################33
if __name__ == "__main__":
    main()